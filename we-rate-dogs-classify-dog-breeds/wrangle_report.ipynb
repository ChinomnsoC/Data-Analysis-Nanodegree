{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We Rate Dogs\n",
    "\n",
    "#### A data-wrangling project by Chinomnso Chinedum\n",
    "\n",
    "### Wrangle Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "This project is part of the Udacity Data Analysis Nanodegree program. The main aim of the project was to wrangle WeRateDogs Twitter data to create interesting and trustworthy analyses and visualizations. Three datasets were used\n",
    "- The twitter archive for WeRateDogs which was manually downloaded from Udacity's servers.\n",
    "- Image predictions dataset that was hosted in Udacity's servers and downloaded programatically,Â  \n",
    "- Each tweet's retweet count and favorite (\"like\") count; gathered by querying Twitter's APIs using the tweet IDs in the WeRateDogs twitter archive dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues Identified\n",
    "A total of 12 quality and tidiness issues where identified. They include:\n",
    "#### Quality issues\n",
    "1. Some tweets are replies and retweets, not original tweets.\n",
    "2. The source_column in `twitter_feed` has some unnecessary HTML code in it.\n",
    "3. Incorrect rating numerators (decimal issues).\n",
    "4. Wrong data types for the following columns: \n",
    "   - a. `timestamp` column in `twitter_feed` has object data type instead of datetime64.\n",
    "   - b. `tweet_id` in all the datasets\n",
    "   - c. `source` in `twitter_feed` - should be changed to category data type.\n",
    "5.  Data about dogs and tweets are in the same dataset.\n",
    "6. Multiple dog stages for some individual records.\n",
    "7. `create_date` column in fave_retweet_data is not needed (after merge) - see below.\n",
    "8. Incorrect Names in `dogs_df`.\n",
    "9. Delete enteries without images\n",
    "\n",
    "#### Tidiness issues\n",
    "1. Dog stage is split into 4 columns in the `twitter_feed` dataset\n",
    "2. The predictions, confidence and dog are split into multiple columns in the `image_predictions` dataset.\n",
    "3. Merge datasets to create a master dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions\n",
    "All the 12 quality and tidyness issues identified were solved and here is how i solved them\n",
    "#### Quality issues\n",
    "1. Some tweets are replies and retweets, not original tweets: I dropped all the rows that have values in the `in_reply_to_status_id`, and `retweeted_status_id` columns. Then, I dropped the `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id`, and the `retweeted_status_timestamp` columns themselves.\n",
    "2. The source_column in `twitter_feed` has some unnecessary HTML code in it: I used str.replace with some regex to remove the HTML code in `source` column\n",
    "3. Incorrect rating numerators (decimal issues): I used the with, display method to confirm that out of range rating numerators are errors. 4 cases were identified as errors and 1 case was an outlier and not an error. For the error cases, i used `.loc()` method to update rating_numerator values.\n",
    "4. Wrong data types for the following columns: \n",
    "   - a. `timestamp` column in `twitter_feed` has object data type instead of datetime64.\n",
    "   - b. `tweet_id` in all the datasets\n",
    "   - c. `source` in `twitter_feed` - should be changed to category data type.\n",
    "   Here, I used the astype() function to change the datatype for each identified column.\n",
    "5.  Data about dogs and tweets are in the same dataset: This issue was addressed primarily to aid the overall cleaning of the dataset. To address this issue, I created a new dataset for dogs by copying out the relevant dog columns i.e; `tweet_id`, `name`, `doggo`, `floofer`, `pupper`, `puppo`, `rating_numerator`, `rating_denominator`. Then, I dropped dog specific columns i.e; `name`, `doggo`, `floofer`, `pupper`, `puppo`, `rating_numerator`, `rating_denominator`.\n",
    "6. Multiple dog stages for some individual records: I created a new column for that identifies unknown and multiple dog stages, as well as the correct ones using the `np.select()` function.\n",
    "7. `create_date` column in fave_retweet_data is not needed (after merge): Droped the column\n",
    "8. Incorrect Names in `dogs_df`: I confirmed the incorrect names and used `str.match()` fuction to replace incorrect names with `None`\n",
    "9. Rows without images in `image_predictions` dataset: Dropped the image predictions without images.\n",
    "\n",
    "#### Tidiness issues\n",
    "1. Dog stage is split into 4 columns in the `twitter_feed` dataset: Dropped the 4 columns since they had been collapsed into one.\n",
    "2. The predictions, confidence and dog are split into multiple columns in the `image_predictions` dataset: I collapsed the `p1`, `p2`, and `p3` columns into prediction round, organized the values in `p1`, `p2`, and `p3` into a single column `breed_predictions`, collapsed the `p1_conf`, `p2_conf`, and `p3_conf` into a single column `confidence` and melted the `p1_dog`, `p2_dog`, and `p3_dog` into column `dog`.\n",
    "3. Merge datasets to create a master dataset: Used the pd.merge() function to create a master dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "\n",
    "I did not anticipate how challenging this project was going to be, but i appreciate how much learning that completing the project made me experience. I was able to query Twitter's API, and this was the first time i was doing that by myself. I also ensured i used functions and methods that I was not familiar with like `np.select` and `str.match`. It was also very useful to get more practice with using `seaborn` for data visualisation. I found the practice of define, code, test to be very useful in organising my wrangling efforts. It also made sense to document all the issues identified first, before going on to solve them. In all, I am very happy about the technical things i learned, and the knowledge on best practices that i gained while completing the project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
